{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "영상 시각화",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOVNAhPi+wOvGd54e5ysPuN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qlqhdl101/face/blob/main/%EC%98%81%EC%83%81_%EC%8B%9C%EA%B0%81%ED%99%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-xMTVeB1qjK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "05442e5f-b134-45e1-db6a-b53542009622"
      },
      "source": [
        "import cv2, dlib\n",
        "import numpy as np\n",
        "from imutils import face_utils\n",
        "from keras.models import load_model\n",
        "\n",
        "IMG_SIZE = (34, 26)\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "model = load_model('models/2018_12_17_22_58_35.h5')\n",
        "model.summary()\n",
        "\n",
        "def crop_eye(img, eye_points):\n",
        "  x1, y1 = np.amin(eye_points, axis=0)\n",
        "  x2, y2 = np.amax(eye_points, axis=0)\n",
        "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "\n",
        "  w = (x2 - x1) * 1.2\n",
        "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
        "\n",
        "  margin_x, margin_y = w / 2, h / 2\n",
        "\n",
        "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
        "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
        "\n",
        "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
        "\n",
        "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
        "\n",
        "  return eye_img, eye_rect\n",
        "\n",
        "# main\n",
        "cap = cv2.VideoCapture('videos/2.mp4')\n",
        "\n",
        "while cap.isOpened():\n",
        "  ret, img_ori = cap.read()\n",
        "\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
        "\n",
        "  img = img_ori.copy()\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  faces = detector(gray)\n",
        "\n",
        "  for face in faces:\n",
        "    shapes = predictor(gray, face)\n",
        "    shapes = face_utils.shape_to_np(shapes)\n",
        "\n",
        "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
        "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
        "\n",
        "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
        "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
        "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
        "\n",
        "    cv2.imshow('l', eye_img_l)\n",
        "    cv2.imshow('r', eye_img_r)\n",
        "\n",
        "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
        "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
        "\n",
        "    pred_l = model.predict(eye_input_l)\n",
        "    pred_r = model.predict(eye_input_r)\n",
        "\n",
        "    # visualize\n",
        "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
        "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
        "\n",
        "    state_l = state_l % pred_l\n",
        "    state_r = state_r % pred_r\n",
        "\n",
        "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
        "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
        "\n",
        "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
        "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
        "\n",
        "  cv2.imshow('result', img)\n",
        "  if cv2.waitKey(1) == ord('q'):\n",
        "    break"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1c202fed7d84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shape_predictor_68_face_landmarks.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/2018_12_17_22_58_35.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unable to open shape_predictor_68_face_landmarks.dat"
          ]
        }
      ]
    }
  ]
}